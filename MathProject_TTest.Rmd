---
title: "Math Project"
author: "Rebecca Rodriguez, Erik Daenitz, Nick Hickman, Seoyeon Yang"
date: "April 2, 2018"
output: html_document
---


## Step 1: Data prep
Get that shit

```{r, tidy = TRUE}

## Stream data into dataframe
treasuryRates = read.csv("./FED-SVENPY.csv") #daily rates

## Subset dataframe to only include 10 year rates
treasury10Y = subset(treasuryRates, select=c(Date,SVENPY10))
colnames(treasury10Y)[c(1,2)] = c("Date", "Value") # rename columns
treasury10Y = treasury10Y[complete.cases(treasury10Y), ] # drop NAs
treasury10Y = treasury10Y[(order(as.Date(treasury10Y$Date))),]
row.names(treasury10Y) = NULL  # re-index the new subset
rates = treasury10Y[((nrow(treasury10Y))-((252*30)+1)):(nrow(treasury10Y)),] # take ~30 past years of treasury data, data takes a year to = 252 days per year and 30 years of past data from the latest observed value
rownames(rates) = NULL # re-index the new subset

# Plot time series for fun visualization
plot(rates$Value ~ as.Date(rates$Date), type="l", main = "U.S. Treasury 10 Year - Yield (%)", xlab = "Date" ,ylab = "Yield (%)")

```

## Step 2: Use Monte Carlo Method to simulate rates

1) Generate X random standard normal variables (X = number of rates over 10 yr period)
2) Repeat 1) 100 times to obtain 245x100 matrix
3) Perform t-test on matrix columns
  a) Perform X-4 t-tests and obtain X-4 test statistics
  b) Grab the max test-statistic for each column to obtain 100 max values

```{r, tidy = TRUE}
set.seed(1000) # set seed to ensure replicable results

#parameters for sampling from standard normal distribution
n = length(rates$Value) # The sample size
sims = 1000 # The number of simulations to replicate, also the length of discrete values in our Lambda Distribution
mu = 0 # The true expected mean value of our normal distribution
s = 1 # The true variance of our normal distribution

#generate random samples of size n
rs = matrix(rnorm(n*sims,mu,s), nrow=n, ncol=sims)

#function to perform t tests
#values: vector of float values
t_tests = function(values){
  index_end = length(values)
  #vectors to hold test statistics
  ttest_stats = c()
  #traverse through list and perform t tests
  for (i in 2:(index_end-2)){
    #perform t test
    ttest_results = t.test(c(values[1:i]), c(values[i+1:index_end]), alternative="two.sided", var.equal=TRUE)
    #add test statistic to list
    ttest_stats = c(ttest_stats, ttest_results$statistic)
  }
  #return max (absolute value) test statistic
  return(max(abs(ttest_stats)))
}

#function to perform anova tests returning max value
#rs:vector of float values
anova_tests = function(rs){
  index_end = length(rs)
  #vectors to hold test statistics
  anovatest_stats = c()
  #traverse through list and perform anova tests
  for (i in 2:(index_end-2)){
    #create factors for anova test
    populations = factor(c(rep(c("a","b"), c(i,index_end-i))))
    #perform anova test
    anova_results = unlist(summary(aov(rs~populations)))
    #put test statistic in list
    anovatest_stats = c(anovatest_stats, anova_results[7])
  }
  #return max test statistic
  return(max(anovatest_stats))
}

library(snow)
cl = makeSOCKcluster(c("localhost","localhost","localhost","localhost"))

#retrieve max test statistics from applying functions to matrix
max_stats_ttest = apply(rs, 2, t_tests)
max_stats_anova = apply(rs, 2, anova_tests)

max_stats_ttest2 = parApply(cl, rs, 2, t_tests)
max_stats_anova2 = parApply(cl, rs, 2, anova_tests)

```


##Step 3: Create lambda distributions from max values

```{r, tidy = TRUE}
#distribution using max values from t-tests
lambdaCDF_ttest = ecdf(max_stats_ttest2)
plot(density(max_stats_ttest2))
plot(lambdaCDF_ttest)

#distribution using max values from anova tests
lambdaCDF_anova = ecdf(max_stats_anova2)
plot(density(max_stats_anova2))
plot(lambdaCDF_anova)

# Create LambdaPVal function to create P-values from our underlyinf Lambda Distribution
lambdaPVal = function (x){
  return(1-lambdaCDF(x))
} 

```


## Step 3a: Create Lambda Distribution from Monte Carlo methods
1) Monte Carlo simulation
- sample size n = length of rates (245)
- simulate 1000 times
- for each simulation, grab max 
- with vector of 1000 maxes, use quantile function to calc critical-values


```{r, tidy = TRUE}
set.seed(1000) # set seed to ensure replicable results

n = 1000 # The sample size
sims = 1000 # The number of simulations to replicate, also the length of discrete values in our Lambda Distribution
mu = 0 # The true expected mean value of our normal distribution
s = 1 # The true variance of our normal distribution

## A Monte Carlo Simulation Function to generate our Lambda Distribution ##
lambdaSimA = function(sims,n,mu,s) {
  l = abs(c(replicate(sims,(max(rnorm(n,mu,s)))),replicate(sims,(min(rnorm(n,mu,s))))))
  return(l)
}

## A Monte Carlo Simulation Function to generate our Lambda Distribution ##
lambdaSimB = function(sims,n,mu,s) {
  l = replicate(sims,(max(abs(rnorm(n,mu,s)))))
  return(l)
}

## Run the function to generate the Lambda Distribution ##
lambdaDistA = lambdaSimA(sims,n,mu,s)

lambdaDistB = lambdaSimB(sims,n,mu,s)

## Generate CDF of our Lambda Distribution later use to generate p-values at various critical values
lambdaCDF = ecdf(lambdaDist)

lambdaCDFb = ecdf(lambdaDistB)

# Create LambdaPVal function to create P-values from our underlyinf Lambda Distribution
lambdaPVal = function (x){
  return(1-lambdaCDF(x))
} 

## Return appropriate critical values of our Lambda Distribution to later test our F-Statistic against  
lambdaQTSa = quantile(lambdaDist, probs = c(0.90, 0.95, 0.975, 0.99, 0.999), na.rm = FALSE, names = FALSE, type = 1)

lambdaQTSb = quantile(lambdaDistB, probs = c(0.90, 0.95, 0.975, 0.99, 0.999), na.rm = FALSE, names = FALSE, type = 1)

lambdaQTSc = quantile(max_stats_ttest2, probs = c(0.90, 0.95, 0.975, 0.99, 0.999), na.rm = FALSE, names = FALSE, type = 1)

lambdaQTSd = quantile(max_stats_anova2, probs = c(0.90, 0.95, 0.975, 0.99, 0.999), na.rm = FALSE, names = FALSE, type = 1)

## Visualization of our friendly Lambda PDF and CDF
par(mfrow=c(2,2))
hist(lambdaDist)
plot(density(lambdaDist))
plot(lambdaCDF)

plot(density(lambdaDistB))
plot(lambdaCDFb)

```

## Step 3b: Create Lambda Distribution from resampling underlying Treasury data

```{r, tidy = TRUE}

## A Resampling Simulation Function to generate our Lambda Distribution ##
lambdaResample = function(sims,x) {
  l = replicate(sims,(sample(x, size=1, replace=FALSE)))
  return(l)
}

## Run the function to generate the Lambda Distribution ##
lambdaDist2 = lambdaResample(sims,treasury10Y$SVENPY10)

## Generate CDF of our Lambda Distribution later use to generate p-values at various critical values
lambdaCDF2 = ecdf(lambdaDist2)

# Create LambdaPVal function to create P-values from our underlyinf Lambda Distribution
lambdaPVal2 = function (x){
  return(1-lambdaCDF2(x))
} 

## Return appropriate critical values of our Lambda Distribution to later test our F-Statistic against  
lambdaQTS2 = quantile(lambdaDist2, probs = c(0.90, 0.95, 0.975, 0.99, 0.999), na.rm = FALSE, names = FALSE, type = 1)

## Visualization of our friendly Lambda PDF and CDF
par(mfrow=c(2,2))
hist(lambdaDist2)
plot(density(lambdaDist2))
plot(lambdaCDF2)

```

## Step 4: Compare test stats to critical values
Function that recursively searches for changepoint
parameters:
rate_list: vector of float values
alpha: significance level for two-sample t-test is set at the 0.05 level
indexer: number of changepoints (default = 0)

```{r tidy=TRUE}
changepoint_search_ttest = function(rate_list, indexer){
  #initialize indexer
  if(indexer == 0) {
        indexer = indexer + 2
  }
  #if list isn't long enough, can't perform test
  if (length(rate_list) < 4){
    return ("Can't perform analysis")
  }
  #otherwise, perform the test
  else{ 
    #perform t test: is mean of first n items different from mean of remaining m items?
    ttest_results = t.test(c(rate_list[1:(indexer)]), c(rate_list[(indexer+1):length(rate_list)]), alternative="two.sided", var.equal=FALSE)
    t_stat = ttest_results$statistic
    
    #get critical val
    c_val = lambdaQTSc[4] # TODO
    #compare test stat to critical val
    if (abs(t_stat) > c_val){ 
      return (cat("value:", rate_list[indexer], "index", indexer))
    }
    #otherwise, no change found
    else{
      #if there aren't enough values left, stop searching
      if(length(rate_list[(indexer+1):length(rate_list)]) < 2){
        return ("Done comparing: no changepoint detected")
      }
      #otherwise, keep searching
      else{
        #cat("indexer:", indexer) #print debugging
        #move down the list
        indexer = indexer + 1
        return (changepoint_search(rate_list, indexer))
      }
    } 
  }
}


#function to perform anova tests returning test statistic on the real data
#rs:vector of float values
anova_F = function(rs){
  index_end = length(rs)
  #vectors to hold test statistics
  anovatest_stats = c()
  #traverse through list and perform anova tests
  for (i in 2:(index_end-2)){
    #create factors for anova test
    populations = factor(c(rep(c("a","b"), c(i,index_end-i))))
    #perform anova test
    anova_results = unlist(summary(aov(rs~populations))) ### Add in critical value comparisons at alpha levels
    #put test statistic in list
    anovatest_stats = c(anovatest_stats, anova_results[9],anova_results[7])
  }
  #return max test statistic
  return(anovatest_stats)
}


changepoint_search_anova = function(rate_list, indexer){
  #initialize indexer
  if(indexer == 0) {
        indexer = indexer + 2
  }
  #if list isn't long enough, can't perform test
  if (length(rate_list) < 4){
    return ("Can't perform analysis")
  }
  #otherwise, perform the test
  else{ 
    #perform anova test: is mean of first n items different from mean of remaining m items?
    populations = factor(c(rep(c("a","b"), c(length(rate_list[1:(indexer)]),length(rate_list[(indexer+1):length(rate_list)])))))
    aov_results = unlist(summary(aov(rs~populations)))
    f_stat = aov_results[7]
    
    #get critical val
    c_val = lambdaQTSd[4] # TODO
    #compare test stat to critical val
    if (abs(f_stat) > c_val){ 
      return (cat("value:", rate_list[indexer], "index", indexer))
    }
    #otherwise, no change found
    else{
      #if there aren't enough values left, stop searching
      if(length(rate_list[(indexer+1):length(rate_list)]) < 2){
        return ("Done comparing: no changepoint detected")
      }
      #otherwise, keep searching
      else{
        #cat("indexer:", indexer) #print debugging
        #move down the list
        indexer = indexer + 1
        return (changepoint_search(rate_list, indexer))
      }
    } 
  }
}

anova_F2 = function(rs){
  index_end = length(rs)
  #vectors to hold test statistics
  anovatest_stats = c()
  #traverse through list and perform anova tests
  for (i in 2:(index_end-2)){
    #create factors for anova test
    populations = factor(c(rep(c("a","b"), c(i,index_end-i))))
    #perform anova test
    anova_results = unlist(summary(aov(rs~populations)))
    f_stat = anova_results[7]
    #get critical val
    c_val = lambdaQTSd[4] # TODO
    #compare test stat to critical val
    if (abs(f_stat) > c_val){ 
      anovatest_stats = c(anovatest_stats, "Changepoint", anova_results[7], anova_results[9])
    }
    #otherwise, no change found
    else{
      anovatest_stats = c(anovatest_stats, "No Changepoint", anova_results[7], anova_results[9])
      }
  }
  #return max test statistic
  return(anovatest_stats)
}


a_result = changepoint_search_anova(rates$Value,0)
rates[3,]

sub1 = rates[1:3,]
sub2 = rates[4:5040,]

changepoint_search_anova(sub1$Value,0)
changepoint_search_anova(sub2$Value,0)


a2_Results = as.data.frame(anova_F2(rates$Value))
anova_results = data.frame(
  x = a2_Results,
  result = c("Result", "FVal", "PVal")[c(1,2,3)]
)

anova_results = unstack(anova_results)
max(anova_results$FVal)
which.max(anova_results$FVal)

par(mfrow=c(2,2))
plot(rates$Value, type="l")
plot(anova_results$FVal, type="l")
plot(anova_results$PVal, type = "l")


## Data for plot
aov_chart = rates[-3,]
aov_chart = rates[1:(n-3),]
aov_chart$Date = as.Date(aov_chart$Date)
aov_chart$Value = as.numeric(aov_chart$Value)
aov_chart$FVal = as.numeric(anova_results$FVal)
aov_chart$PVal = as.numeric(anova_results$PVal)
aov_chart$FVal = round(aov_chart$FVal, digits = 3)
aov_chart$PVal = round(aov_chart$PVal, digits = 6)


library(ggplot2)
library(reshape2)
aov_chart_prep = melt(aov_chart, id = "Date", measure = c("Value", "FVal", "PVal"))
ggplot(aov_chart_prep, aes(Date, value, colour = variable)) + geom_line()


chart = ggplot() + 
  geom_line(data = aov_chart, aes(x = Date, y = Value), color = "red") + scale_y_continuous
  geom_line(data = aov_chart, aes(x = Date, y = FVal), color = "blue") + scale_y_continuous(sec.axis = sec_axis(~./1000)) +
  geom_line(data = aov_chart, aes(x = Date, y = PVal), color = "green") +
  xlab('Date')
chart

print(rates[90,])
sub1 = subset(rates[0:result_index,])
sub2 = subset(rates[result_index+1:length(rates),])

a_result1 = anova_F(sub1$Value)
result_index = which.max(a_result1)
print(rates[result_index,])

a_result2 = anova_F2(sub2$Value)
result_index = which.max(a_result2)
print(rates[result_index,])


```