---
title: "Math Project"
author: "Rebecca Rodriguez, Erik Daenitz, Nick Hickman, Seoyeon Yang"
date: "April 2, 2018"
output: html_document
---


## Step 1: Data prep
Get that shit

```{r, tidy = TRUE}

## Stream data into dataframe
treasuryRates = read.csv("./FED-SVENPY.csv") #daily rates

## Subset dataframe to only include 10 year rates
treasury10Y = subset(treasuryRates, select=c(Date,SVENPY10))
colnames(treasury10Y)[c(1,2)] = c("Date", "Value") # rename columns
treasury10Y = treasury10Y[complete.cases(treasury10Y), ] # drop NAs
treasury10Y = treasury10Y[(order(as.Date(treasury10Y$Date))),]
row.names(treasury10Y) = NULL  # re-index the new subset
rates = treasury10Y[((nrow(treasury10Y))-((252*30)+1)):(nrow(treasury10Y)),] # take ~30 past years of treasury data, data takes a year to = 252 days per year and 30 years of past data from the latest observed value
rownames(rates) = NULL # re-index the new subset

# Plot time series for fun visualization
plot(rates$Value ~ as.Date(rates$Date), type="l", main = "U.S. Treasury 10 Year - Yield (%)", xlab = "Date" ,ylab = "Yield (%)")

```

## Step 2: Use Monte Carlo Method to simulate rates

1) Generate X random standard normal variables (X = number of rates over 10 yr period)
2) Repeat 1) 100 times to obtain 245x100 matrix
3) Perform t-test on matrix columns
  a) Perform X-4 t-tests and obtain X-4 test statistics
  b) Grab the max test-statistic for each column to obtain 100 max values

```{r, tidy = TRUE}
set.seed(1000) # set seed to ensure replicable results

#parameters for sampling from standard normal distribution
n = length(rates$Value) # The sample size
sims = 1000 # The number of simulations to replicate, also the length of discrete values in our Lambda Distribution
mu = 0 # The true expected mean value of our normal distribution
s = 1 # The true variance of our normal distribution

#generate random samples of size n
rs = matrix(rnorm(n*sims,mu,s), nrow=n, ncol=sims)

#function to perform t tests
#values: vector of float values
t_tests = function(values){
  index_end = length(values)
  #vectors to hold test statistics
  ttest_stats = c()
  #traverse through list and perform t tests
  for (i in 2:(index_end-2)){
    #perform t test
    ttest_results = t.test(c(values[1:i]), c(values[i+1:index_end]), alternative="two.sided", var.equal=TRUE)
    #add test statistic to list
    ttest_stats = c(ttest_stats, ttest_results$statistic)
  }
  #return max (absolute value) test statistic
  return(max(abs(ttest_stats)))
}

library(snow)
cl = makeSOCKcluster(c("localhost","localhost","localhost","localhost"))

#retrieve max test statistics from applying functions to matrix
max_stats_ttest2 = parApply(cl, rs, 2, t_tests)

```


##Step 3: Create lambda distributions from max values

```{r, tidy = TRUE}
#distribution using max values from t-tests
lambdaCDF_ttest = ecdf(max_stats_ttest2)
plot(density(max_stats_ttest2))
plot(lambdaCDF_ttest)

# Create LambdaPVal function to create P-values from our underlyinf Lambda Distribution
lambdaPVal = function (x){
  return(1-lambdaCDF(x))
} 

lambdaQTSc = quantile(max_stats_ttest2, probs = c(0.90, 0.95, 0.975, 0.99, 0.999), na.rm = FALSE, names = FALSE, type = 1)

```

## Step 4: Compare test stats to critical values
Function that recursively searches for changepoint
parameters:
rate_list: vector of float values
alpha: significance level for two-sample t-test is set at the 0.05 level
indexer: number of changepoints (default = 0)

```{r tidy=TRUE}
#function to perform anova tests returning test statistic on the real data

#Redo as T-Test!

anova_F2 = function(rs){
  index_end = length(rs)
  #vectors to hold test statistics
  anovatest_stats = c()
  #traverse through list and perform anova tests
  for (i in 2:(index_end-2)){
    #create factors for anova test
    populations = factor(c(rep(c("a","b"), c(i,index_end-i))))
    #perform anova test
    anova_results = unlist(summary(aov(rs~populations)))
    f_stat = anova_results[7]
    #get critical val
    c_val = lambdaQTSd[4] # TODO
    #compare test stat to critical val
    if (abs(f_stat) > c_val){ 
      anovatest_stats = c(anovatest_stats, "Changepoint", anova_results[7], anova_results[9])
    }
    #otherwise, no change found
    else{
      anovatest_stats = c(anovatest_stats, "No Changepoint", anova_results[7], anova_results[9])
      }
  }
  #return max test statistic
  return(anovatest_stats)
}


a_result = changepoint_search_anova(rates$Value,0)
rates[3,]

sub1 = rates[1:3,]
sub2 = rates[4:5040,]

changepoint_search_anova(sub1$Value,0)
changepoint_search_anova(sub2$Value,0)


a2_Results = as.data.frame(anova_F2(rates$Value))
anova_results = data.frame(
  x = a2_Results,
  result = c("Result", "FVal", "PVal")[c(1,2,3)]
)

anova_results = unstack(anova_results)
max(anova_results$FVal)
which.max(anova_results$FVal)

par(mfrow=c(2,2))
plot(rates$Value, type="l")
plot(anova_results$FVal, type="l")
plot(anova_results$PVal, type = "l")


## Data for plot
aov_chart = rates[-3,]
aov_chart = rates[1:(n-3),]
aov_chart$Date = as.Date(aov_chart$Date)
aov_chart$Value = as.numeric(aov_chart$Value)
aov_chart$FVal = as.numeric(anova_results$FVal)
aov_chart$PVal = as.numeric(anova_results$PVal)
aov_chart$FVal = round(aov_chart$FVal, digits = 3)
aov_chart$PVal = round(aov_chart$PVal, digits = 6)


library(ggplot2)
library(reshape2)
aov_chart_prep = melt(aov_chart, id = "Date", measure = c("Value", "FVal", "PVal"))
ggplot(aov_chart_prep, aes(Date, value, colour = variable)) + geom_line()


chart = ggplot() + 
  geom_line(data = aov_chart, aes(x = Date, y = Value), color = "red") + scale_y_continuous
  geom_line(data = aov_chart, aes(x = Date, y = FVal), color = "blue") + scale_y_continuous(sec.axis = sec_axis(~./1000)) +
  geom_line(data = aov_chart, aes(x = Date, y = PVal), color = "green") +
  xlab('Date')
chart


```