---
title: "It's the Economy Stupid: A Time Series Analysis of 10 Year Montlhy Treasury Rates with ANOVA"
author: "Rebecca Rodriguez, Erik Daenitz, Nick Hickman, Seoyeon Yang"
date: "April 22, 2018"
output: html_document
---


## Step 1: Data prep
Stream U.S. 10 yeare Treasury data into data frame. We use daily end-of-day observations for yields. We then subset that data to take the most recent ~20 years of daily observations.

```{r, tidy = TRUE}
## Stream data into dataframe
treasuryRates_m = read.csv("./10YTreasuryYield.csv") # Monthly 10Y Treasury rates

## Subset dataframe to only include 10 year rates
treasury10Y_m = treasuryRates_m
colnames(treasury10Y_m)[c(1,2)] = c("Date", "Value") # rename columns
treasury10Y_m = treasury10Y_m[complete.cases(treasury10Y_m), ] # drop NAs
#treasury10Y_m = treasury10Y_m[(order(as.Date(treasury10Y_m$Date))),]
#row.names(treasury10Y_m) = NULL  # re-index the new subset
rates_m = treasury10Y_m[689:1060,] # take ~30 past years of treasury data, data takes a year to = 252 days per year and 30 years of past data from the latest observed value
rownames(rates_m) = NULL # re-index the new subset

# Plot time series for fun visualization
plot(rates_m$Value, type="l", main = "U.S. Treasury 10 Year - Yield (%)", xlab = "Date" ,ylab = "Yield (%)")

```

## Step 2: Use Monte Carlo Method to simulate rates

1) Generate X random standard normal variables (X = number of observations over 20 yr period)
2) Repeat 1) 1000 times to obtain 7562x1000 matrix
3) Perform cascading One Way ANOVA test within each matrix column
  a) Perform X-4 tests and obtain X-4 test statistics
  b) Grab the max test-statistic for each column to obtain 1000 max values to form our Lambda Distribution with

```{r, tidy = TRUE}
set.seed(1000) # Set seed to ensure replicable results

# Parameters for sampling from standard normal distribution
n_m = length(rates_m$Value) # The sample size
sims = 1000 # The number of simulations to replicate, also the length of discrete values in our Lambda Distribution
mu = 0 # The true expected mean value of our normal distribution
s = 1 # The true variance of our normal distribution

# Generate random samples of size n
rs_m = matrix(rnorm(n_m*sims,mu,s), nrow=n_m, ncol=sims)

# Function to perform cascading ANOVA tests through each vector and return max F value
# rs: vector of float values
anova_tests = function(rs){
  index_end = length(rs)
  #vectors to hold test statistics
  anovatest_stats = c()
  #traverse through list and perform anova tests
  for (i in 2:(index_end-2)){
    #create factors for anova test
    populations = factor(c(rep(c("a","b"), c(i,index_end-i))))
    #perform anova test
    anova_results = unlist(summary(aov(rs~populations)))
    #put test statistic in list
    anovatest_stats = c(anovatest_stats, anova_results[7])
  }
  #return max test statistic
  return(max(anovatest_stats))
}

## Now run the function over every vector in the matrix ##

# Load the library "snow"" to parallelize the computation using all available cores of the local machine
library(snow)
# Open up sockets to the 4 local processor cores
## Note: only enter "localhost" = to the number of cores on your processor
cl = makeSOCKcluster(c("localhost","localhost","localhost","localhost"))

# Retrieve max test statistics by applying the function to each matrix vector
max_stats_anova2_m = parApply(cl, rs_m, 2, anova_tests)
```


##Step 3: Create Lambda distribution CDF, PDF and critical values from simulated Lamda Distribution
Now that we have achieved the simulation of the Lamda Distribution we must assemble a CDF and take quantiles of the PDF at different alpha critical value levels.

Our chosen alpha levels:
$$\alpha=0.10, 0.05, 0.025, 0.01, 0.001$$

```{r, tidy = TRUE}
# CDF and plotted PDF using max values Lamda Distribution from ANOVA tests
lambdaCDF_anova_m = ecdf(max_stats_anova2_m)
plot(density(max_stats_anova2_m), main = "Lambda PDF", xlab = "Critical Value" , ylab = "Density of Observations")
plot(lambdaCDF_anova_m, main = "Lambda CDF", xlab = "Critical Value" , ylab = "Accumulated Area")

# Spare P-value function to create P-values from our underlying Lambda Distribution at any specified critical value
## Note: This function is used later in subsequent code, it is just created to provide quick intuition on associated p-values with any critical value if the user wishes to get a better sense of the distribution areas.
lambdaPVal_m = function (x){
  return(1-lambdaCDF_anova_m(x))
} 

# Return appropriate critical values of our Lambda Distribution to later test our F-Statistics on live data against 
lambdaQTSd_m = quantile(max_stats_anova2_m, probs = c(0.90, 0.95, 0.975, 0.99, 0.999), na.rm = FALSE, names = FALSE, type = 1)
```

##Step 4: Perform ANOVA tests on Treasury data
```{r, tidy = TRUE}
# Function to run on live data that collects max f-values and corresponding index
anova_test_live = function(rs){
  index_end = length(rs)
  #vectors to hold test statistics
  anovatest_stats = c()
  #traverse through list and perform anova tests
  for (i in 2:(index_end-2)){
    #create factors for anova test
    populations = factor(c(rep(c("a","b"), c(i,index_end-i))))
    #perform anova test
    anova_results = unlist(summary(aov(rs~populations)))
    #put test statistic in list
    anovatest_stats = c(anovatest_stats, anova_results[7])
  }
  
  #return vector of max test statistic and corresponding index
  max_stat = max(anovatest_stats)
  return(c(max_stat, (match(max_stat, anovatest_stats)+1))) #index of last element in first population
}

#find biggest changepoint in data
max1_m = anova_test_live(rates_m$Value)

#create two subsets from max1
pop1a_m = rates_m$Value[(1:max1_m[2])]
pop1b_m = rates_m$Value[(max1_m[2]+1):(length(rates_m$Value))]

#perform anova tests on each subset and grab max test statistics
max2_m = anova_test_live(pop1a_m)
max3_m = anova_test_live(pop1b_m)

#create two subsets from max2
pop2a_m = pop1a[1:max2_m[2]]
pop2b_m = pop1a[(max2_m[2]+1):length(pop1a_m)]

#create two subsets from max3
pop3a_m = pop1b_m[1:max3_m[2]]
pop3b_m = pop1b[(max3_m[2]+1):length(pop1b_m)]

#perform anova tests on each new subset and grab max test statisticss
max4_m = anova_test_live(pop2a_m)
max5_m = anova_test_live(pop2b_m)
max6_m = anova_test_live(pop3a_m)
max7_m = anova_test_live(pop3b_m)

# Retrieve index from original data
# for example, grab index within original data for max5
# which(rates_m$Value == pop3b[max7[2]])

### Our First Change Point ####
firstChangePoint_m = rates_m[max1_m[2],]
firstChangePValue_m = lambdaPVal_m(max1_m[1])
print(firstChangePoint_m)
print(firstChangePValue_m)

changePointIndices_m = c(max1_m[2],(which(rates_m$Value == pop1a_m[max2_m[2]])),(which(rates_m$Value == pop1b_m[max3_m[2]])),(which(rates_m$Value == pop2a_m[max4_m[2]])),(which(rates_m$Value == pop2b_m[max5_m[2]])),(which(rates_m$Value == pop3a_m[max6_m[2]])),(which(rates_m$Value == pop3b_m[max7_m[2]])))

library(R.utils)
rates_m$Changepoint_m = 0
rates_m$Changepoint_m[changePointIndices_m[1]] = 1
rates_m$Changepoint_m[changePointIndices_m[2]] = 1
rates_m$Changepoint_m[changePointIndices_m[3]] = 1
rates_m$Changepoint_m[changePointIndices_m[4]] = 1
rates_m$Changepoint_m[changePointIndices_m[5]] = 1

library(ggplot2)
library(grid)
library(dplyr)
library(lubridate)

df_m = data.frame(DateTime = mdy("05-01-1987") + months(0:371), series1 = rates_m$Value, series2 = rates_m$Changepoint_m)

#' Create the two plots.
plot1 = df_m %>%
  select(DateTime, series1) %>%
  ggplot() +
  geom_line(aes(x = DateTime, y = series1), size = 0.5, alpha = 0.75) +
  ylab("10Y UST (Yield,%)") +
  theme_minimal() +
  theme(axis.title.x = element_blank())

plot2 = df_m %>%
  select(DateTime, series2) %>%
  ggplot() +
  geom_line(aes(x = DateTime, y = series2), size = 0.5, alpha = 0.75) +
  ylab("Changepoint Signal") +
  theme_minimal() +
  theme(axis.title.x = element_blank())

grid.newpage()
grid.draw(rbind(ggplotGrob(plot1), ggplotGrob(plot2), size = "last"))

```

##Step 5: Check Assumptions of ANOVA on our First Changepoint
```{r, tidy = TRUE}

i_m = max1_m[2] # The index of our first changepoint
index_end_m = length(rates_m$Value)
cp_pop_m = factor(c(rep(c("a","b"), c(i_m,index_end_m-i))))

cp_aov_m = aov(rates_m$Value ~ cp_pop_m)
ap_aov_res_m = resid(cp_aov_m)

# Testing for normality of the Treasury sample residuals
qqnorm(ap_aov_res_m) # a built-in function to generate qq-plots
qqline(ap_aov_res_m) # add a straight line to the qq-plots

shapiro.test(ap_aov_res_m) # Shapiro-Wilks test for normality

##We see from the QQplot of residuals that the sample residuals appear non-normal.
## The Shapiro-Wilks test, with a p-value that is small, affirms this interpretation.

### Test for Homeskedasticity

plot(ap_aov_res_m, ylab="Residuals", xlab="Fitted Value") 
abline(0, 0)

plot(cp_aov_m)

## Our Residuals vs. Fitted values plot shows a relatively patterned distribution which indicates some dependency in our data
## We conclude that the assumption of homoskedasticity appears implausible
## Yet, the consruction of our procedures is robust and we can still conclude that our changepoint is valid

```