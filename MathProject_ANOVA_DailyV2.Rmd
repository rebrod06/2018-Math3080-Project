---
title: "It's the Economy Stupid: A Time Series Analysis of 10 Year Daily Treasury Rates with ANOVA"
author: "Rebecca Rodriguez, Erik Daenitz, Nick Hickman, Seoyeon Yang"
date: "April 22, 2018"
output: html_document
---


## Step 1: Data prep
Stream U.S. 10 yeare Treasury data into data frame. We use daily end-of-day observations for yields. We then subset that data to take the most recent ~20 years of daily observations.

```{r, tidy = TRUE}
## Stream data into dataframe
treasuryRates = read.csv("./FED-SVENPY.csv") #daily rates

## Subset dataframe to only include 10 year rates
treasury10Y = subset(treasuryRates, select=c(Date,SVENPY10))
colnames(treasury10Y)[c(1,2)] = c("Date", "Value") # rename columns
treasury10Y = treasury10Y[complete.cases(treasury10Y), ] # drop NAs
treasury10Y = treasury10Y[(order(as.Date(treasury10Y$Date))),]
row.names(treasury10Y) = NULL  # re-index the new subset
rates = treasury10Y[((nrow(treasury10Y))-((252*30)+1)):(nrow(treasury10Y)),] # take ~30 past years of treasury data, data takes a year to = 252 days per year and 30 years of past data from the latest observed value
rownames(rates) = NULL # re-index the new subset

# Plot time series for fun visualization
plot(rates$Value ~ as.Date(rates$Date), type="l", main = "U.S. Treasury 10 Year - Yield (%)", xlab = "Date" ,ylab = "Yield (%)")

```

## Step 2: Use Monte Carlo Method to simulate rates

1) Generate X random standard normal variables (X = number of observations over 20 yr period)
2) Repeat 1) 1000 times to obtain 7562x1000 matrix
3) Perform cascading One Way ANOVA test within each matrix column
  a) Perform X-4 tests and obtain X-4 test statistics
  b) Grab the max test-statistic for each column to obtain 1000 max values to form our Lambda Distribution with

```{r, tidy = TRUE}
set.seed(1000) # Set seed to ensure replicable results

# Parameters for sampling from standard normal distribution
n = length(rates$Value) # The sample size
sims = 1000 # The number of simulations to replicate, also the length of discrete values in our Lambda Distribution
mu = 0 # The true expected mean value of our normal distribution
s = 1 # The true variance of our normal distribution

# Generate random samples of size n
rs = matrix(rnorm(n*sims,mu,s), nrow=n, ncol=sims)

# Function to perform cascading ANOVA tests through each vector and return max F value
# rs: vector of float values
anova_tests = function(rs){
  index_end = length(rs)
  #vectors to hold test statistics
  anovatest_stats = c()
  #traverse through list and perform anova tests
  for (i in 2:(index_end-2)){
    #create factors for anova test
    populations = factor(c(rep(c("a","b"), c(i,index_end-i))))
    #perform anova test
    anova_results = unlist(summary(aov(rs~populations)))
    #put test statistic in list
    anovatest_stats = c(anovatest_stats, anova_results[7])
  }
  #return max test statistic
  return(max(anovatest_stats))
}

## Now run the function over every vector in the matrix ##

# Load the library "snow"" to parallelize the computation using all available cores of the local machine
library(snow)
# Open up sockets to the 4 local processor cores
## Note: only enter "localhost" = to the number of cores on your processor
cl = makeSOCKcluster(c("localhost","localhost","localhost","localhost"))

# Retrieve max test statistics by applying the function to each matrix vector
## Note: expect to wait about 45 mins on a 2.7ghz quad core processor ##
max_stats_anova2 = parApply(cl, rs, 2, anova_tests)
```


##Step 3: Create Lambda distribution CDF, PDF and critical values from simulated Lamda Distribution
Now that we have achieved the simulation of the Lamda Distribution we must assemble a CDF and take quantiles of the PDF at different alpha critical value levels.

Our chosen alpha levels:
$$\alpha=0.10, 0.05, 0.025, 0.01, 0.001$$

```{r, tidy = TRUE}
# CDF and plotted PDF using max values Lamda Distribution from ANOVA tests
lambdaCDF_anova = ecdf(max_stats_anova2)
plot(density(max_stats_anova2), main = "Lambda PDF", xlab = "Critical Value" , ylab = "Density of Observations")
plot(lambdaCDF_anova, main = "Lambda CDF", xlab = "Critical Value" , ylab = "Accumulated Area")

# Spare P-value function to create P-values from our underlying Lambda Distribution at any specified critical value
## Note: This function is not used in subsequent code, it is just created to provide quick intuition on associated p-values with any critical value if the user wishes to get a better sense of the distribution areas.
lambdaPVal = function (x){
  return(1-lambdaCDF_anova(x))
} 

# Return appropriate critical values of our Lambda Distribution to later test our F-Statistics on live data against 
lambdaQTSd = quantile(max_stats_anova2, probs = c(0.90, 0.95, 0.975, 0.99, 0.999), na.rm = FALSE, names = FALSE, type = 1)
```


##Step 4: Perform ANOVA tests on Treasury data

```{r, tidy = TRUE}
# Function to run on live data that collects max f-values and corresponding index
anova_test_live = function(rs){
  index_end = length(rs)
  #vectors to hold test statistics
  anovatest_stats = c()
  #traverse through list and perform anova tests
  for (i in 2:(index_end-2)){
    #create factors for anova test
    populations = factor(c(rep(c("a","b"), c(i,index_end-i))))
    #perform anova test
    anova_results = unlist(summary(aov(rs~populations)))
    #put test statistic in list
    anovatest_stats = c(anovatest_stats, anova_results[7])
  }
  
  #return vector of max test statistic and corresponding index
  max_stat = max(anovatest_stats)
  return(c(max_stat, (match(max_stat, anovatest_stats)+1))) #index of last element in first population
}

#find biggest changepoint in data
max1 = anova_test_live(rates$Value)

#create two subsets from max1
pop1a = rates$Value[(1:max1[2])]
pop1b = rates$Value[(max1[2]+1):(length(rates$Value))]

#perform anova tests on each subset and grab max test statistics
max2 = anova_test_live(pop1a)
max3 = anova_test_live(pop1b)

#create two subsets from max2
pop2a = pop1a[1:max2[2]]
pop2b = pop1a[(max2[2]+1):length(pop1a)]

#create two subsets from max3
pop3a = pop1b[1:max3[2]]
pop3b = pop1b[(max3[2]+1):length(pop1b)]

#perform anova tests on each new subset and grab max test statisticss
max4 = anova_test_live(pop2a)
max5 = anova_test_live(pop2b)
max6 = anova_test_live(pop3a)
max7 = anova_test_live(pop3b)

# Retrieve index from original data
# for example, grab index within original data for max5
# which(rates_m$Value == pop3b[max7[2]])

### Our First Change Point ####
firstChangePoint = rates[max1[2],]
firstChangePValue = lambdaPVal(max1[1])
print(firstChangePoint)
print(firstChangePValue)

changePointIndices = c(max1[2],(which(rates$Value == pop1a[max2[2]])),(which(rates$Value == pop1b[max3[2]])),(which(rates$Value == pop2a[max4[2]])),(which(rates$Value == pop2b[max5[2]])),(which(rates$Value == pop3a[max6[2]])),(which(rates$Value == pop3b[max7[2]])))

library(R.utils)
rates$Changepoint = 0
rates$Changepoint[changePointIndices[1]] = 1
rates$Changepoint[changePointIndices[2]] = 1
rates$Changepoint[changePointIndices[3]] = 1
rates$Changepoint[changePointIndices[4]] = 1
rates$Changepoint[changePointIndices[5]] = 1

library(ggplot2)
library(grid)
library(dplyr)
library(lubridate)

df = data.frame(DateTime = mdy("12-02-1987") + days(0:7561), series1 = rates$Value, series2 = rates$Changepoint)

#' Create the two plots.
plot1 = df %>%
  select(DateTime, series1) %>%
  ggplot() +
  geom_line(aes(x = DateTime, y = series1), size = 0.5, alpha = 0.75) +
  ylab("10Y UST (Yield,%)") +
  theme_minimal() +
  theme(axis.title.x = element_blank())

plot2 = df %>%
  select(DateTime, series2) %>%
  ggplot() +
  geom_line(aes(x = DateTime, y = series2), size = 0.5, alpha = 0.75) +
  ylab("Changepoint Signal") +
  theme_minimal() +
  theme(axis.title.x = element_blank())

grid.newpage()
grid.draw(rbind(ggplotGrob(plot1), ggplotGrob(plot2), size = "last"))
```

##Step 5: Check Assumptions of ANOVA on our First Changepoint
```{r, tidy = TRUE}

i = max1[2] # The index of our first changepoint
index_end = length(rates$Value)
cp_pop = factor(c(rep(c("a","b"), c(i,index_end-i))))

cp_aov = aov(rates$Value ~ cp_pop)
ap_aov_res = resid(cp_aov)

# Testing for normality of the Treasury sample residuals
qqnorm(ap_aov_res) # a built-in function to generate qq-plots
qqline(ap_aov_res) # add a straight line to the qq-plots

shapiro.test(ap_aov_res) # Shapiro-Wilks test for normality

##We see from the QQplot of residuals that the sample residuals appear non-normal.
## The Shapiro-Wilks test, with a p-value that is small, affirms this interpretation.

### Test for Homeskedasticity

plot(ap_aov_res, ylab="Residuals", xlab="Fitted Value") 
abline(0, 0)

plot(cp_aov)

## Our Residuals vs. Fitted values plot shows a relatively patterned distribution which indicates some dependency in our data
## We conclude that the assumption of homoskedasticity appears implausible
## Yet, the consruction of our procedures is robust and we can still conclude that our changepoint is valid

```

##Step 6: Test New Model on Out of Sample Data

```{r, tidy = TRUE}
## Stream out of sample data into dataframe
treasury10Y_new = read.csv("./10YNew.csv") #daily rates
colnames(treasury10Y_new)[c(1,2)] = c("Date", "Value") # rename columns
treasury10Y_new = treasury10Y_new[complete.cases(treasury10Y_new), ] # drop NAs
row.names(treasury10Y_new) = NULL  # re-index the new subset

rates_new = rbind(rates[,c(1:2)], treasury10Y_new)

#find biggest changepoint in data from end of previous dataset
max1 = anova_test_live(treasury10Y_new$Value)

```